# -*- coding: utf-8 -*-
"""DeepByWriter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aT5i_gKVP2NWKSlvsiRkIU8vBxulb8L3
"""

import sys
sys.version
!pip install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl

!pip install -U pillow
import PIL
print(PIL.PILLOW_VERSION)
#!pip uninstall Pillow

!pip3 install torchvision

!{sys.executable} -m pip install torchtext==0.2.3
#pip install torchtext==0.2.3

# %matplotlib inline
import torchvision
import torchvision.datasets as dset
from torchvision.datasets import ImageFolder
import torchvision.transforms as transforms
from torch.utils.data import DataLoader,Dataset
import matplotlib.pyplot as plt
import torchvision.utils
import numpy as np
import random
from PIL import Image
import torch
from torch.autograd import Variable
import PIL.ImageOps    
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
from google.colab import drive
drive.mount('/content/drive')


class SiameseNetwork(nn.Module):
  def __init__(self):
    super(SiameseNetwork, self).__init__()
    self.cnn1 = nn.Sequential(
    nn.ReflectionPad2d(1),
    nn.Conv2d(1,4,kernel_size=3),
    nn.ReLU(inplace=True),
    nn.BatchNorm2d(4),
    nn.Dropout2d(p=.2),
    
    
    nn.ReflectionPad2d(1),
    nn.Conv2d(4,8,kernel_size=3),
    nn.ReLU(inplace=True),
    nn.BatchNorm2d(8),
    nn.Dropout2d(p=.2),
    
        
        
    nn.ReflectionPad2d(1),
    nn.Conv2d(8,8, kernel_size=3),
    nn.ReLU(inplace=True),
    nn.BatchNorm2d(8),
    nn.Dropout2d(p=.2),
    
    )
    self.fully_c =nn.Sequential(
    nn.Linear(8*100*100,500),
    nn.ReLU(inplace=True),
        
    nn.Linear(500,500),
    nn.ReLU(inplace=True),
    nn.Linear(500,7) #number? 
    )
    
  def forward_once(self,data):
    output= self.cnn1(data)
    output=output.view(output.size()[0],-1)
    output= self.fully_c(output)
    return output
    
  def forward(self,input1,input2):
    output1 = self.forward_once(input1)
    output2 = self.forward_once(input2)
    return output1, output2

class ContrastiveLoss(torch.nn.Module):
  def __init__(self,margin=2.0):
    super(ContrastiveLoss,self).__init__()
    self.margin = margin
    
  def forward(self,output1,output2,label):
    distance = F.pairwise_distance(output1,output2)
    loss_contrastive = torch.mean((1-label)*torch.pow(distance,2) + (label)*torch.pow(torch.clamp(self.margin-distance,min=0.0),2))
    return loss_contrastive

class SiameseNetworkDataset(Dataset):
  def __init__(self,imageFolderDataset,transform=None,should_invert=True):
    self.imageFolderDataset = imageFolderDataset
    self.should_invert = should_invert
    self.transform=transform
  
  def __getitem__(self,index):
    img0_tuple = random.choice(self.imageFolderDataset.imgs)
    
    #randomise getting one class.
    should_get_same_class = random.randint(0,1)
    
    if should_get_same_class:
      while True:
        img1_tuple =random.choice(self.imageFolderDataset.imgs)
        if img0_tuple[1] == img1_tuple[1]:
          break
    else:
      img1_tuple =random.choice(self.imageFolderDataset.imgs)
    
    img0 =Image.open(img0_tuple[0])
    img1 =Image.open(img1_tuple[0])
    
    img0 = img0.convert("L")
    img1 = img1.convert("L")
    
    if self.should_invert:
      img0 =PIL.ImageOps.invert(img0)
      img1 =PIL.ImageOps.invert(img1)
    if self.transform is not None:
      img0 = self.transform(img0)
      img1 = self.transform(img1)
      
    return img0, img1,torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))
  
  def __len__(self):
    return len(self.imageFolderDataset.imgs)

!ls "/content/drive/My Drive/ColabNotebooks/data/testing_1"
print("PyTorch version: ")
print(torch.__version__)
print("CUDA Version: ")
print(torch.version.cuda)
print("cuDNN version is: ")
print(torch.backends.cudnn.version())

def imshow(img,text=None,should_save=False):
  npimg = img.numpy()
  plt.axis("off")
  if text:
    plt.text(75, 8,text,style='italic',fontweight='bold',bbox={'facecolor':'white','alpha':0.8,'pad':10})
  plt.imshow(np.transpose(npimg,(1,2,0)))
  plt.show()
def show_plot(iteration,loss):
  plt.plot(iteration,loss)
  plt.show()

folder_dataset = dset.ImageFolder(root="/content/drive/My Drive/ColabNotebooks/DataProcessed/final_data/training_1/")
siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,transform=transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()]),should_invert=False)

vis_dataloader = DataLoader(siamese_dataset,shuffle=True,num_workers=2,batch_size=2)
dataiter = iter(vis_dataloader)

example_batch=next(dataiter)
concatenated=torch.cat((example_batch[0],example_batch[1]),0)
imshow(torchvision.utils.make_grid(concatenated))
print(example_batch[2].numpy)

train_dataloader = DataLoader(siamese_dataset,shuffle=True,num_workers =4,batch_size=1)

net = SiameseNetwork().cuda()

criterion = ContrastiveLoss()

optimizer = optim.Adam(net.parameters(),lr=0.0005)

counter = []

loss_history = []

iteration_number=0

for epoch in range(0,50):
  for i, data in enumerate(train_dataloader,0):
    img0,img1,label = data
    img0,img1,label=img0.cuda(),img1.cuda(),label.cuda()
    
    optimizer.zero_grad()
    output1,output2 =net(img0,img1)
    
    loss_contrastive = criterion(output1,output2,label)
    
    loss_contrastive.backward()
    
    optimizer.step()
    if i%2 ==0:
      #print("Epoch number {}\n Current loss {} \n".format(epoch,loss_contrastive.item()))
      print("Epoch number {}\n Current loss {}\n".format(epoch,loss_contrastive.item()))
      iteration_number +=2
      counter.append(iteration_number)
      #loss_history.append(loss_contrastive.item())
      loss_history.append(loss_contrastive.item())
show_plot(counter,loss_history)

folder_dataset_test = dset.ImageFolder(root="/content/drive/My Drive/ColabNotebooks/DataProcessed/final_data/testing_1/")
siamese_dataset=SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,transform=transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()]),should_invert=False)
test_dataloader = DataLoader(siamese_dataset,num_workers=6,batch_size=1,shuffle=False)
dataiter = iter(test_dataloader)
x0,_,label1= next(dataiter)
correct = 0
total =0
path_name ="/content/drive/My Drive/"  
for i in range(0,20):
  _,x1,label2=next(dataiter)
  concatenated = torch.cat((x0,x1),0)
  output1,output2=net(Variable(x0).cuda(),Variable(x1).cuda())
  distance = F.pairwise_distance(output1,output2)
  #distance = F.pairwise_distance(output1,output2)
  currDist = distance.cpu()
  for j in range(currDist.size()[0]):
    if(currDist.data.numpy()[j]<1):
      if(label1.cpu().data.numpy()[j]==1):
        correct+=1
        total+=1
      else:
        total+=1
    else:
      if(label1.cpu().data.numpy()[j]==0):
        correct+=1
        total+=1
      else:
        total+=1
    
  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(distance.item()))
  print("Accuracy of the network on test images is : %d %%" %(100*correct/total))
  #print("MY {}".format(label1))
  #image_path = path_name.format(label2)+"/out_"+str(i)+".png"
  #torchvision.utils.save_image(x0,'/content/drive/My Drive/out.png')
  #torchvision.utils.save_image(x0,image_path)
  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(distance.item()))

